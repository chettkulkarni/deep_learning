{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras MultiClass Classification binary class entropy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SenWjo3PNNVT",
        "colab_type": "code",
        "outputId": "3b1399b7-611e-4711-c756-e859fa5b9cf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import random\n",
        "random.seed(1)\n",
        "!pip install -q git+https://github.com/tensorflow/docs\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import pydot\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.plots\n",
        "import tensorflow_docs.modeling\n",
        "import pathlib\n",
        "from sklearn import tree, preprocessing\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "tf.random.set_seed(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6KYWnuIRcNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_wine"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD_wBaqqRfwt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_data = load_wine()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBZrAxbgTRaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_class(x):\n",
        "  if x=='class_0':\n",
        "    return 0\n",
        "  elif x=='class_1':\n",
        "    return 1\n",
        "  else:\n",
        "    return 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHReRZZLRi1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = pd.DataFrame(data=raw_data['data'],columns=raw_data['feature_names'])\n",
        "data = features\n",
        "data['target']=raw_data['target']\n",
        "data['class']=data['target'].map(lambda ind: raw_data['target_names'][ind])\n",
        "data['class']=data['class'].map(lambda x: set_class(x) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfsr2hfhS-Gn",
        "colab_type": "code",
        "outputId": "2ef24edb-44a9-4f6f-9213-25629ce2e59a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data['class'].unique()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsDCNflpSGx7",
        "colab_type": "code",
        "outputId": "2b5ee914-1256-451c-9bd2-488bafa9d4a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp1iAkjDT_tN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = data.drop(['class'], axis=1).values\n",
        "Y = data['class'].values\n",
        "X_train, X_test, y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B93-LmWwOUV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense,Dropout, Flatten\n",
        "def build_model_binary_cross_entropy():\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  model.add(Dense(178, activation='relu',input_shape=(14,)))\n",
        "  model.add(Dense(25, activation='relu'))\n",
        "  # model.add(Dense(20, activation='relu'))\n",
        "  # model.add(Dense(20, activation='relu'))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  # optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['mae', 'mse','accuracy'])\n",
        "  \n",
        "  model.summary()\n",
        "\n",
        "  model.fit(X_train, y_train, epochs=300)\n",
        "\n",
        "  plotter = tfdocs.plots.HistoryPlotter(smoothing_std=2)\n",
        "\n",
        "  test_predictions = model.predict(X_test).flatten()\n",
        "\n",
        "  a = plt.axes(aspect='equal')\n",
        "  plt.scatter(Y_test, test_predictions)\n",
        "  plt.xlabel('True Values [MPG]')\n",
        "  plt.ylabel('Predictions [MPG]')\n",
        "  lims = [0, 2]\n",
        "  plt.xlim(lims)\n",
        "  plt.ylim(lims)\n",
        "  _ = plt.plot(lims, lims)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ifeS_DROo_Z",
        "colab_type": "code",
        "outputId": "3e7061e6-64bd-4410-ad1f-d4c5ec0a238f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "build_model_binary_cross_entropy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 178)               2670      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 25)                4475      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 26        \n",
            "=================================================================\n",
            "Total params: 7,171\n",
            "Trainable params: 7,171\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 45.5845 - mae: 1.0000 - mse: 1.5849 - accuracy: 0.2925\n",
            "Epoch 2/300\n",
            "106/106 [==============================] - 0s 96us/step - loss: 4.0566 - mae: 0.6209 - mse: 0.6579 - accuracy: 0.4434\n",
            "Epoch 3/300\n",
            "106/106 [==============================] - 0s 84us/step - loss: 8.9048 - mae: 0.5849 - mse: 0.5849 - accuracy: 0.4151\n",
            "Epoch 4/300\n",
            "106/106 [==============================] - 0s 100us/step - loss: 10.6155 - mae: 0.5849 - mse: 0.5849 - accuracy: 0.4151\n",
            "Epoch 5/300\n",
            "106/106 [==============================] - 0s 99us/step - loss: 9.5682 - mae: 0.5849 - mse: 0.5849 - accuracy: 0.4151\n",
            "Epoch 6/300\n",
            "106/106 [==============================] - 0s 86us/step - loss: 5.6449 - mae: 0.5849 - mse: 0.5849 - accuracy: 0.4151\n",
            "Epoch 7/300\n",
            "106/106 [==============================] - 0s 100us/step - loss: 1.5435 - mae: 0.5838 - mse: 0.5828 - accuracy: 0.4151\n",
            "Epoch 8/300\n",
            "106/106 [==============================] - 0s 80us/step - loss: 1.7358 - mae: 0.6360 - mse: 0.9090 - accuracy: 0.5377\n",
            "Epoch 9/300\n",
            "106/106 [==============================] - 0s 77us/step - loss: -1.7838 - mae: 0.4888 - mse: 0.4843 - accuracy: 0.5283\n",
            "Epoch 10/300\n",
            "106/106 [==============================] - 0s 84us/step - loss: 1.0054 - mae: 0.5849 - mse: 0.5849 - accuracy: 0.4151\n",
            "Epoch 11/300\n",
            "106/106 [==============================] - 0s 76us/step - loss: 1.0572 - mae: 0.5849 - mse: 0.5849 - accuracy: 0.4151\n",
            "Epoch 12/300\n",
            "106/106 [==============================] - 0s 71us/step - loss: -1.4310 - mae: 0.5832 - mse: 0.5818 - accuracy: 0.4151\n",
            "Epoch 13/300\n",
            "106/106 [==============================] - 0s 94us/step - loss: -2.5151 - mae: 0.3590 - mse: 0.3545 - accuracy: 0.6509\n",
            "Epoch 14/300\n",
            "106/106 [==============================] - 0s 91us/step - loss: -3.1775 - mae: 0.3865 - mse: 0.3731 - accuracy: 0.6321\n",
            "Epoch 15/300\n",
            "106/106 [==============================] - 0s 117us/step - loss: -2.7755 - mae: 0.5843 - mse: 0.5837 - accuracy: 0.4151\n",
            "Epoch 16/300\n",
            "106/106 [==============================] - 0s 91us/step - loss: -3.6425 - mae: 0.5646 - mse: 0.5602 - accuracy: 0.4340\n",
            "Epoch 17/300\n",
            "106/106 [==============================] - 0s 95us/step - loss: -3.1910 - mae: 0.3583 - mse: 0.3508 - accuracy: 0.6509\n",
            "Epoch 18/300\n",
            "106/106 [==============================] - 0s 99us/step - loss: -4.2663 - mae: 0.3583 - mse: 0.3506 - accuracy: 0.6415\n",
            "Epoch 19/300\n",
            "106/106 [==============================] - 0s 71us/step - loss: -3.9171 - mae: 0.5845 - mse: 0.5840 - accuracy: 0.4151\n",
            "Epoch 20/300\n",
            "106/106 [==============================] - 0s 74us/step - loss: -2.9206 - mae: 0.5849 - mse: 0.5849 - accuracy: 0.4151\n",
            "Epoch 21/300\n",
            "106/106 [==============================] - 0s 69us/step - loss: -4.0935 - mae: 0.5849 - mse: 0.5848 - accuracy: 0.4151\n",
            "Epoch 22/300\n",
            "106/106 [==============================] - 0s 70us/step - loss: -5.1152 - mae: 0.3778 - mse: 0.3635 - accuracy: 0.6226\n",
            "Epoch 23/300\n",
            "106/106 [==============================] - 0s 79us/step - loss: -5.8683 - mae: 0.3975 - mse: 0.3938 - accuracy: 0.6038\n",
            "Epoch 24/300\n",
            "106/106 [==============================] - 0s 113us/step - loss: -5.6119 - mae: 0.5834 - mse: 0.5820 - accuracy: 0.4151\n",
            "Epoch 25/300\n",
            "106/106 [==============================] - 0s 83us/step - loss: -6.4378 - mae: 0.5137 - mse: 0.5079 - accuracy: 0.4811\n",
            "Epoch 26/300\n",
            "106/106 [==============================] - 0s 83us/step - loss: -6.7776 - mae: 0.3855 - mse: 0.3780 - accuracy: 0.6132\n",
            "Epoch 27/300\n",
            "106/106 [==============================] - 0s 84us/step - loss: -7.6384 - mae: 0.4638 - mse: 0.4505 - accuracy: 0.5377\n",
            "Epoch 28/300\n",
            "106/106 [==============================] - 0s 84us/step - loss: -7.7046 - mae: 0.5458 - mse: 0.5408 - accuracy: 0.4528\n",
            "Epoch 29/300\n",
            "106/106 [==============================] - 0s 75us/step - loss: -8.0324 - mae: 0.4811 - mse: 0.4798 - accuracy: 0.5189\n",
            "Epoch 30/300\n",
            "106/106 [==============================] - 0s 93us/step - loss: -8.6982 - mae: 0.4366 - mse: 0.4236 - accuracy: 0.5755\n",
            "Epoch 31/300\n",
            "106/106 [==============================] - 0s 80us/step - loss: -9.0285 - mae: 0.5105 - mse: 0.5073 - accuracy: 0.4906\n",
            "Epoch 32/300\n",
            "106/106 [==============================] - 0s 122us/step - loss: -9.3514 - mae: 0.5163 - mse: 0.5085 - accuracy: 0.4717\n",
            "Epoch 33/300\n",
            "106/106 [==============================] - 0s 83us/step - loss: -10.1934 - mae: 0.4904 - mse: 0.4833 - accuracy: 0.5094\n",
            "Epoch 34/300\n",
            "106/106 [==============================] - 0s 105us/step - loss: -11.0487 - mae: 0.4914 - mse: 0.4860 - accuracy: 0.5094\n",
            "Epoch 35/300\n",
            "106/106 [==============================] - 0s 75us/step - loss: -12.0542 - mae: 0.4836 - mse: 0.4769 - accuracy: 0.5094\n",
            "Epoch 36/300\n",
            "106/106 [==============================] - 0s 80us/step - loss: -12.5823 - mae: 0.4450 - mse: 0.4346 - accuracy: 0.5566\n",
            "Epoch 37/300\n",
            "106/106 [==============================] - 0s 75us/step - loss: -13.4322 - mae: 0.4361 - mse: 0.4262 - accuracy: 0.5660\n",
            "Epoch 38/300\n",
            "106/106 [==============================] - 0s 87us/step - loss: -14.0601 - mae: 0.4883 - mse: 0.4816 - accuracy: 0.5189\n",
            "Epoch 39/300\n",
            "106/106 [==============================] - 0s 83us/step - loss: -15.0074 - mae: 0.5002 - mse: 0.4991 - accuracy: 0.5000\n",
            "Epoch 40/300\n",
            "106/106 [==============================] - 0s 83us/step - loss: -15.8977 - mae: 0.4685 - mse: 0.4613 - accuracy: 0.5283\n",
            "Epoch 41/300\n",
            "106/106 [==============================] - 0s 98us/step - loss: -16.5765 - mae: 0.4790 - mse: 0.4758 - accuracy: 0.5189\n",
            "Epoch 42/300\n",
            "106/106 [==============================] - 0s 98us/step - loss: -17.4983 - mae: 0.3922 - mse: 0.3879 - accuracy: 0.6132\n",
            "Epoch 43/300\n",
            "106/106 [==============================] - 0s 130us/step - loss: -17.9659 - mae: 0.4641 - mse: 0.4554 - accuracy: 0.5377\n",
            "Epoch 44/300\n",
            "106/106 [==============================] - 0s 87us/step - loss: -19.8546 - mae: 0.4870 - mse: 0.4824 - accuracy: 0.5189\n",
            "Epoch 45/300\n",
            "106/106 [==============================] - 0s 82us/step - loss: -20.0126 - mae: 0.3961 - mse: 0.3908 - accuracy: 0.6038\n",
            "Epoch 46/300\n",
            "106/106 [==============================] - 0s 86us/step - loss: -21.9268 - mae: 0.4565 - mse: 0.4497 - accuracy: 0.5472\n",
            "Epoch 47/300\n",
            "106/106 [==============================] - 0s 85us/step - loss: -22.4866 - mae: 0.5270 - mse: 0.5219 - accuracy: 0.4811\n",
            "Epoch 48/300\n",
            "106/106 [==============================] - 0s 84us/step - loss: -23.6653 - mae: 0.5350 - mse: 0.5325 - accuracy: 0.4623\n",
            "Epoch 49/300\n",
            "106/106 [==============================] - 0s 79us/step - loss: -24.2660 - mae: 0.4024 - mse: 0.3983 - accuracy: 0.5943\n",
            "Epoch 50/300\n",
            "106/106 [==============================] - 0s 73us/step - loss: -25.0207 - mae: 0.3698 - mse: 0.3682 - accuracy: 0.6321\n",
            "Epoch 51/300\n",
            "106/106 [==============================] - 0s 67us/step - loss: -27.0054 - mae: 0.5188 - mse: 0.5188 - accuracy: 0.4811\n",
            "Epoch 52/300\n",
            "106/106 [==============================] - 0s 81us/step - loss: -28.9835 - mae: 0.5137 - mse: 0.5105 - accuracy: 0.4811\n",
            "Epoch 53/300\n",
            "106/106 [==============================] - 0s 85us/step - loss: -29.6292 - mae: 0.3918 - mse: 0.3884 - accuracy: 0.6132\n",
            "Epoch 54/300\n",
            "106/106 [==============================] - 0s 79us/step - loss: -32.1316 - mae: 0.4780 - mse: 0.4754 - accuracy: 0.5189\n",
            "Epoch 55/300\n",
            "106/106 [==============================] - 0s 80us/step - loss: -33.8542 - mae: 0.4831 - mse: 0.4807 - accuracy: 0.5189\n",
            "Epoch 56/300\n",
            "106/106 [==============================] - 0s 120us/step - loss: -35.3903 - mae: 0.4676 - mse: 0.4605 - accuracy: 0.5377\n",
            "Epoch 57/300\n",
            "106/106 [==============================] - 0s 129us/step - loss: -36.6684 - mae: 0.4810 - mse: 0.4809 - accuracy: 0.5189\n",
            "Epoch 58/300\n",
            "106/106 [==============================] - 0s 84us/step - loss: -38.6566 - mae: 0.4904 - mse: 0.4903 - accuracy: 0.5094\n",
            "Epoch 59/300\n",
            "106/106 [==============================] - 0s 88us/step - loss: -40.9262 - mae: 0.4864 - mse: 0.4839 - accuracy: 0.5094\n",
            "Epoch 60/300\n",
            "106/106 [==============================] - 0s 82us/step - loss: -42.4016 - mae: 0.4589 - mse: 0.4564 - accuracy: 0.5377\n",
            "Epoch 61/300\n",
            "106/106 [==============================] - 0s 77us/step - loss: -43.4174 - mae: 0.4230 - mse: 0.4215 - accuracy: 0.5755\n",
            "Epoch 62/300\n",
            "106/106 [==============================] - 0s 67us/step - loss: -46.7144 - mae: 0.3852 - mse: 0.3805 - accuracy: 0.6226\n",
            "Epoch 63/300\n",
            "106/106 [==============================] - 0s 84us/step - loss: -45.8548 - mae: 0.5404 - mse: 0.5382 - accuracy: 0.4623\n",
            "Epoch 64/300\n",
            "106/106 [==============================] - 0s 101us/step - loss: -48.9050 - mae: 0.5549 - mse: 0.5535 - accuracy: 0.4434\n",
            "Epoch 65/300\n",
            "106/106 [==============================] - 0s 82us/step - loss: -53.9002 - mae: 0.4599 - mse: 0.4564 - accuracy: 0.5377\n",
            "Epoch 66/300\n",
            "106/106 [==============================] - 0s 78us/step - loss: -54.6478 - mae: 0.3774 - mse: 0.3774 - accuracy: 0.6226\n",
            "Epoch 67/300\n",
            "106/106 [==============================] - 0s 94us/step - loss: -58.8886 - mae: 0.4717 - mse: 0.4717 - accuracy: 0.5283\n",
            "Epoch 68/300\n",
            "106/106 [==============================] - 0s 95us/step - loss: -61.9371 - mae: 0.4991 - mse: 0.4982 - accuracy: 0.5000\n",
            "Epoch 69/300\n",
            "106/106 [==============================] - 0s 85us/step - loss: -65.3583 - mae: 0.4808 - mse: 0.4805 - accuracy: 0.5189\n",
            "Epoch 70/300\n",
            "106/106 [==============================] - 0s 86us/step - loss: -67.6264 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 71/300\n",
            "106/106 [==============================] - 0s 94us/step - loss: -71.2889 - mae: 0.4418 - mse: 0.4404 - accuracy: 0.5566\n",
            "Epoch 72/300\n",
            "106/106 [==============================] - 0s 90us/step - loss: -74.0851 - mae: 0.4704 - mse: 0.4688 - accuracy: 0.5283\n",
            "Epoch 73/300\n",
            "106/106 [==============================] - 0s 103us/step - loss: -77.6344 - mae: 0.5094 - mse: 0.5094 - accuracy: 0.4906\n",
            "Epoch 74/300\n",
            "106/106 [==============================] - 0s 118us/step - loss: -81.5221 - mae: 0.4817 - mse: 0.4812 - accuracy: 0.5189\n",
            "Epoch 75/300\n",
            "106/106 [==============================] - 0s 99us/step - loss: -85.7530 - mae: 0.4584 - mse: 0.4555 - accuracy: 0.5377\n",
            "Epoch 76/300\n",
            "106/106 [==============================] - 0s 100us/step - loss: -89.4980 - mae: 0.4701 - mse: 0.4687 - accuracy: 0.5283\n",
            "Epoch 77/300\n",
            "106/106 [==============================] - 0s 100us/step - loss: -90.4085 - mae: 0.5283 - mse: 0.5281 - accuracy: 0.4717\n",
            "Epoch 78/300\n",
            "106/106 [==============================] - 0s 87us/step - loss: -97.3413 - mae: 0.5094 - mse: 0.5094 - accuracy: 0.4906\n",
            "Epoch 79/300\n",
            "106/106 [==============================] - 0s 82us/step - loss: -99.8720 - mae: 0.4282 - mse: 0.4252 - accuracy: 0.5755\n",
            "Epoch 80/300\n",
            "106/106 [==============================] - 0s 111us/step - loss: -106.5646 - mae: 0.4151 - mse: 0.4151 - accuracy: 0.5849\n",
            "Epoch 81/300\n",
            "106/106 [==============================] - 0s 107us/step - loss: -112.8386 - mae: 0.4906 - mse: 0.4906 - accuracy: 0.5094\n",
            "Epoch 82/300\n",
            "106/106 [==============================] - 0s 103us/step - loss: -116.7731 - mae: 0.5111 - mse: 0.5097 - accuracy: 0.4906\n",
            "Epoch 83/300\n",
            "106/106 [==============================] - 0s 98us/step - loss: -122.8681 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 84/300\n",
            "106/106 [==============================] - 0s 83us/step - loss: -129.7578 - mae: 0.4850 - mse: 0.4827 - accuracy: 0.5189\n",
            "Epoch 85/300\n",
            "106/106 [==============================] - 0s 92us/step - loss: -135.8834 - mae: 0.4528 - mse: 0.4528 - accuracy: 0.5472\n",
            "Epoch 86/300\n",
            "106/106 [==============================] - 0s 109us/step - loss: -142.4511 - mae: 0.4639 - mse: 0.4626 - accuracy: 0.5377\n",
            "Epoch 87/300\n",
            "106/106 [==============================] - 0s 91us/step - loss: -149.8192 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 88/300\n",
            "106/106 [==============================] - 0s 71us/step - loss: -155.3608 - mae: 0.4812 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 89/300\n",
            "106/106 [==============================] - 0s 109us/step - loss: -163.6955 - mae: 0.4606 - mse: 0.4585 - accuracy: 0.5377\n",
            "Epoch 90/300\n",
            "106/106 [==============================] - 0s 91us/step - loss: -168.1786 - mae: 0.4070 - mse: 0.4058 - accuracy: 0.5943\n",
            "Epoch 91/300\n",
            "106/106 [==============================] - 0s 90us/step - loss: -174.4241 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 92/300\n",
            "106/106 [==============================] - 0s 104us/step - loss: -184.7721 - mae: 0.5005 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 93/300\n",
            "106/106 [==============================] - 0s 86us/step - loss: -192.9217 - mae: 0.4445 - mse: 0.4435 - accuracy: 0.5566\n",
            "Epoch 94/300\n",
            "106/106 [==============================] - 0s 89us/step - loss: -195.1175 - mae: 0.3774 - mse: 0.3774 - accuracy: 0.6226\n",
            "Epoch 95/300\n",
            "106/106 [==============================] - 0s 103us/step - loss: -206.7854 - mae: 0.4717 - mse: 0.4717 - accuracy: 0.5283\n",
            "Epoch 96/300\n",
            "106/106 [==============================] - 0s 96us/step - loss: -219.4724 - mae: 0.4523 - mse: 0.4518 - accuracy: 0.5472\n",
            "Epoch 97/300\n",
            "106/106 [==============================] - 0s 96us/step - loss: -225.8311 - mae: 0.4340 - mse: 0.4340 - accuracy: 0.5660\n",
            "Epoch 98/300\n",
            "106/106 [==============================] - 0s 108us/step - loss: -233.0567 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 99/300\n",
            "106/106 [==============================] - 0s 79us/step - loss: -246.1497 - mae: 0.4811 - mse: 0.4810 - accuracy: 0.5189\n",
            "Epoch 100/300\n",
            "106/106 [==============================] - 0s 82us/step - loss: -256.8738 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 101/300\n",
            "106/106 [==============================] - 0s 77us/step - loss: -264.0751 - mae: 0.5094 - mse: 0.5094 - accuracy: 0.4906\n",
            "Epoch 102/300\n",
            "106/106 [==============================] - 0s 88us/step - loss: -269.9834 - mae: 0.5189 - mse: 0.5189 - accuracy: 0.4811\n",
            "Epoch 103/300\n",
            "106/106 [==============================] - 0s 77us/step - loss: -286.6303 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 104/300\n",
            "106/106 [==============================] - 0s 81us/step - loss: -301.0410 - mae: 0.4717 - mse: 0.4717 - accuracy: 0.5283\n",
            "Epoch 105/300\n",
            "106/106 [==============================] - 0s 106us/step - loss: -312.6754 - mae: 0.4057 - mse: 0.4057 - accuracy: 0.5943\n",
            "Epoch 106/300\n",
            "106/106 [==============================] - 0s 73us/step - loss: -330.7240 - mae: 0.4390 - mse: 0.4366 - accuracy: 0.5566\n",
            "Epoch 107/300\n",
            "106/106 [==============================] - 0s 95us/step - loss: -346.2131 - mae: 0.4998 - mse: 0.4997 - accuracy: 0.5000\n",
            "Epoch 108/300\n",
            "106/106 [==============================] - 0s 102us/step - loss: -352.1165 - mae: 0.5189 - mse: 0.5189 - accuracy: 0.4811\n",
            "Epoch 109/300\n",
            "106/106 [==============================] - 0s 79us/step - loss: -370.9014 - mae: 0.5189 - mse: 0.5189 - accuracy: 0.4811\n",
            "Epoch 110/300\n",
            "106/106 [==============================] - 0s 91us/step - loss: -391.8505 - mae: 0.4906 - mse: 0.4906 - accuracy: 0.5094\n",
            "Epoch 111/300\n",
            "106/106 [==============================] - 0s 88us/step - loss: -409.7575 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 112/300\n",
            "106/106 [==============================] - 0s 82us/step - loss: -426.3051 - mae: 0.4717 - mse: 0.4717 - accuracy: 0.5283\n",
            "Epoch 113/300\n",
            "106/106 [==============================] - 0s 83us/step - loss: -444.0025 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 114/300\n",
            "106/106 [==============================] - 0s 89us/step - loss: -465.3922 - mae: 0.4690 - mse: 0.4671 - accuracy: 0.5283\n",
            "Epoch 115/300\n",
            "106/106 [==============================] - 0s 83us/step - loss: -488.6778 - mae: 0.4438 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 116/300\n",
            "106/106 [==============================] - 0s 76us/step - loss: -495.7989 - mae: 0.5094 - mse: 0.5094 - accuracy: 0.4906\n",
            "Epoch 117/300\n",
            "106/106 [==============================] - 0s 96us/step - loss: -518.9383 - mae: 0.5189 - mse: 0.5189 - accuracy: 0.4811\n",
            "Epoch 118/300\n",
            "106/106 [==============================] - 0s 107us/step - loss: -543.7827 - mae: 0.5094 - mse: 0.5094 - accuracy: 0.4906\n",
            "Epoch 119/300\n",
            "106/106 [==============================] - 0s 72us/step - loss: -574.8176 - mae: 0.4906 - mse: 0.4906 - accuracy: 0.5094\n",
            "Epoch 120/300\n",
            "106/106 [==============================] - 0s 85us/step - loss: -597.8236 - mae: 0.4717 - mse: 0.4717 - accuracy: 0.5283\n",
            "Epoch 121/300\n",
            "106/106 [==============================] - 0s 92us/step - loss: -624.9890 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 122/300\n",
            "106/106 [==============================] - 0s 88us/step - loss: -635.9252 - mae: 0.4057 - mse: 0.4057 - accuracy: 0.5943\n",
            "Epoch 123/300\n",
            "106/106 [==============================] - 0s 98us/step - loss: -661.7952 - mae: 0.4057 - mse: 0.4057 - accuracy: 0.5943\n",
            "Epoch 124/300\n",
            "106/106 [==============================] - 0s 96us/step - loss: -689.4510 - mae: 0.4528 - mse: 0.4528 - accuracy: 0.5472\n",
            "Epoch 125/300\n",
            "106/106 [==============================] - 0s 130us/step - loss: -717.1850 - mae: 0.5094 - mse: 0.5094 - accuracy: 0.4906\n",
            "Epoch 126/300\n",
            "106/106 [==============================] - 0s 82us/step - loss: -739.7308 - mae: 0.4903 - mse: 0.4901 - accuracy: 0.5094\n",
            "Epoch 127/300\n",
            "106/106 [==============================] - 0s 104us/step - loss: -772.0232 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 128/300\n",
            "106/106 [==============================] - 0s 82us/step - loss: -786.6104 - mae: 0.4340 - mse: 0.4340 - accuracy: 0.5660\n",
            "Epoch 129/300\n",
            "106/106 [==============================] - 0s 94us/step - loss: -817.4761 - mae: 0.4340 - mse: 0.4340 - accuracy: 0.5660\n",
            "Epoch 130/300\n",
            "106/106 [==============================] - 0s 78us/step - loss: -854.0427 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 131/300\n",
            "106/106 [==============================] - 0s 87us/step - loss: -883.7917 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 132/300\n",
            "106/106 [==============================] - 0s 80us/step - loss: -913.7982 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 133/300\n",
            "106/106 [==============================] - 0s 75us/step - loss: -940.4639 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 134/300\n",
            "106/106 [==============================] - 0s 94us/step - loss: -974.0824 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 135/300\n",
            "106/106 [==============================] - 0s 83us/step - loss: -1011.4265 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 136/300\n",
            "106/106 [==============================] - 0s 84us/step - loss: -1047.2740 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 137/300\n",
            "106/106 [==============================] - 0s 103us/step - loss: -1083.4842 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 138/300\n",
            "106/106 [==============================] - 0s 126us/step - loss: -1120.7831 - mae: 0.4906 - mse: 0.4906 - accuracy: 0.5094\n",
            "Epoch 139/300\n",
            "106/106 [==============================] - 0s 78us/step - loss: -1162.6118 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 140/300\n",
            "106/106 [==============================] - 0s 82us/step - loss: -1192.2356 - mae: 0.4245 - mse: 0.4245 - accuracy: 0.5755\n",
            "Epoch 141/300\n",
            "106/106 [==============================] - 0s 114us/step - loss: -1211.7428 - mae: 0.3868 - mse: 0.3868 - accuracy: 0.6132\n",
            "Epoch 142/300\n",
            "106/106 [==============================] - 0s 101us/step - loss: -1257.8441 - mae: 0.4245 - mse: 0.4245 - accuracy: 0.5755\n",
            "Epoch 143/300\n",
            "106/106 [==============================] - 0s 86us/step - loss: -1310.6740 - mae: 0.4483 - mse: 0.4460 - accuracy: 0.5472\n",
            "Epoch 144/300\n",
            "106/106 [==============================] - 0s 90us/step - loss: -1362.7280 - mae: 0.4811 - mse: 0.4810 - accuracy: 0.5189\n",
            "Epoch 145/300\n",
            "106/106 [==============================] - 0s 102us/step - loss: -1407.1973 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 146/300\n",
            "106/106 [==============================] - 0s 81us/step - loss: -1450.3310 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 147/300\n",
            "106/106 [==============================] - 0s 78us/step - loss: -1503.2103 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 148/300\n",
            "106/106 [==============================] - 0s 86us/step - loss: -1547.0054 - mae: 0.4528 - mse: 0.4528 - accuracy: 0.5472\n",
            "Epoch 149/300\n",
            "106/106 [==============================] - 0s 76us/step - loss: -1598.8369 - mae: 0.4340 - mse: 0.4340 - accuracy: 0.5660\n",
            "Epoch 150/300\n",
            "106/106 [==============================] - 0s 89us/step - loss: -1644.7969 - mae: 0.4717 - mse: 0.4717 - accuracy: 0.5283\n",
            "Epoch 151/300\n",
            "106/106 [==============================] - 0s 90us/step - loss: -1682.6279 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 152/300\n",
            "106/106 [==============================] - 0s 89us/step - loss: -1747.6375 - mae: 0.5094 - mse: 0.5094 - accuracy: 0.4906\n",
            "Epoch 153/300\n",
            "106/106 [==============================] - 0s 101us/step - loss: -1801.5857 - mae: 0.4528 - mse: 0.4528 - accuracy: 0.5472\n",
            "Epoch 154/300\n",
            "106/106 [==============================] - 0s 118us/step - loss: -1835.8038 - mae: 0.4151 - mse: 0.4151 - accuracy: 0.5849\n",
            "Epoch 155/300\n",
            "106/106 [==============================] - 0s 101us/step - loss: -1902.2761 - mae: 0.4340 - mse: 0.4340 - accuracy: 0.5660\n",
            "Epoch 156/300\n",
            "106/106 [==============================] - 0s 111us/step - loss: -1978.0319 - mae: 0.4906 - mse: 0.4906 - accuracy: 0.5094\n",
            "Epoch 157/300\n",
            "106/106 [==============================] - 0s 118us/step - loss: -2011.6956 - mae: 0.5094 - mse: 0.5094 - accuracy: 0.4906\n",
            "Epoch 158/300\n",
            "106/106 [==============================] - 0s 112us/step - loss: -2061.6352 - mae: 0.5189 - mse: 0.5189 - accuracy: 0.4811\n",
            "Epoch 159/300\n",
            "106/106 [==============================] - 0s 101us/step - loss: -2155.4518 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 160/300\n",
            "106/106 [==============================] - 0s 90us/step - loss: -2237.5184 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 161/300\n",
            "106/106 [==============================] - 0s 97us/step - loss: -2288.3346 - mae: 0.4340 - mse: 0.4340 - accuracy: 0.5660\n",
            "Epoch 162/300\n",
            "106/106 [==============================] - 0s 91us/step - loss: -2361.5637 - mae: 0.4340 - mse: 0.4340 - accuracy: 0.5660\n",
            "Epoch 163/300\n",
            "106/106 [==============================] - 0s 85us/step - loss: -2426.6234 - mae: 0.4906 - mse: 0.4906 - accuracy: 0.5094\n",
            "Epoch 164/300\n",
            "106/106 [==============================] - 0s 86us/step - loss: -2466.7094 - mae: 0.5094 - mse: 0.5094 - accuracy: 0.4906\n",
            "Epoch 165/300\n",
            "106/106 [==============================] - 0s 81us/step - loss: -2584.2737 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 166/300\n",
            "106/106 [==============================] - 0s 88us/step - loss: -2653.4434 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 167/300\n",
            "106/106 [==============================] - 0s 107us/step - loss: -2699.8990 - mae: 0.4340 - mse: 0.4340 - accuracy: 0.5660\n",
            "Epoch 168/300\n",
            "106/106 [==============================] - 0s 104us/step - loss: -2808.0062 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 169/300\n",
            "106/106 [==============================] - 0s 79us/step - loss: -2879.0289 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 170/300\n",
            "106/106 [==============================] - 0s 82us/step - loss: -2938.7325 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 171/300\n",
            "106/106 [==============================] - 0s 73us/step - loss: -2975.7753 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 172/300\n",
            "106/106 [==============================] - 0s 86us/step - loss: -3096.2045 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 173/300\n",
            "106/106 [==============================] - 0s 67us/step - loss: -3176.9821 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 174/300\n",
            "106/106 [==============================] - 0s 74us/step - loss: -3159.6339 - mae: 0.3962 - mse: 0.3962 - accuracy: 0.6038\n",
            "Epoch 175/300\n",
            "106/106 [==============================] - 0s 73us/step - loss: -3297.5542 - mae: 0.4096 - mse: 0.4073 - accuracy: 0.5943\n",
            "Epoch 176/300\n",
            "106/106 [==============================] - 0s 79us/step - loss: -3396.6452 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 177/300\n",
            "106/106 [==============================] - 0s 96us/step - loss: -3452.7935 - mae: 0.5080 - mse: 0.5067 - accuracy: 0.4906\n",
            "Epoch 178/300\n",
            "106/106 [==============================] - 0s 92us/step - loss: -3522.4127 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 179/300\n",
            "106/106 [==============================] - 0s 85us/step - loss: -3630.1473 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 180/300\n",
            "106/106 [==============================] - 0s 71us/step - loss: -3722.1969 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 181/300\n",
            "106/106 [==============================] - 0s 76us/step - loss: -3835.8244 - mae: 0.4717 - mse: 0.4717 - accuracy: 0.5283\n",
            "Epoch 182/300\n",
            "106/106 [==============================] - 0s 100us/step - loss: -3916.5297 - mae: 0.4340 - mse: 0.4340 - accuracy: 0.5660\n",
            "Epoch 183/300\n",
            "106/106 [==============================] - 0s 109us/step - loss: -4018.4481 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 184/300\n",
            "106/106 [==============================] - 0s 94us/step - loss: -4112.0939 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 185/300\n",
            "106/106 [==============================] - 0s 96us/step - loss: -4187.9804 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 186/300\n",
            "106/106 [==============================] - 0s 90us/step - loss: -4335.5077 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 187/300\n",
            "106/106 [==============================] - 0s 99us/step - loss: -4399.3073 - mae: 0.4340 - mse: 0.4340 - accuracy: 0.5660\n",
            "Epoch 188/300\n",
            "106/106 [==============================] - 0s 99us/step - loss: -4385.1015 - mae: 0.3868 - mse: 0.3868 - accuracy: 0.6132\n",
            "Epoch 189/300\n",
            "106/106 [==============================] - 0s 82us/step - loss: -4475.6852 - mae: 0.3774 - mse: 0.3774 - accuracy: 0.6226\n",
            "Epoch 190/300\n",
            "106/106 [==============================] - 0s 85us/step - loss: -4612.5483 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 191/300\n",
            "106/106 [==============================] - 0s 83us/step - loss: -4774.8239 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 192/300\n",
            "106/106 [==============================] - 0s 80us/step - loss: -4841.4766 - mae: 0.5094 - mse: 0.5094 - accuracy: 0.4906\n",
            "Epoch 193/300\n",
            "106/106 [==============================] - 0s 79us/step - loss: -4978.8662 - mae: 0.4906 - mse: 0.4906 - accuracy: 0.5094\n",
            "Epoch 194/300\n",
            "106/106 [==============================] - 0s 74us/step - loss: -5104.9878 - mae: 0.4528 - mse: 0.4528 - accuracy: 0.5472\n",
            "Epoch 195/300\n",
            "106/106 [==============================] - 0s 93us/step - loss: -5221.8105 - mae: 0.4528 - mse: 0.4528 - accuracy: 0.5472\n",
            "Epoch 196/300\n",
            "106/106 [==============================] - 0s 126us/step - loss: -5268.2491 - mae: 0.4906 - mse: 0.4906 - accuracy: 0.5094\n",
            "Epoch 197/300\n",
            "106/106 [==============================] - 0s 91us/step - loss: -5416.3363 - mae: 0.5094 - mse: 0.5094 - accuracy: 0.4906\n",
            "Epoch 198/300\n",
            "106/106 [==============================] - 0s 96us/step - loss: -5562.5146 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 199/300\n",
            "106/106 [==============================] - 0s 89us/step - loss: -5622.5990 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 200/300\n",
            "106/106 [==============================] - 0s 88us/step - loss: -5684.0500 - mae: 0.4057 - mse: 0.4057 - accuracy: 0.5943\n",
            "Epoch 201/300\n",
            "106/106 [==============================] - 0s 85us/step - loss: -5811.9019 - mae: 0.4340 - mse: 0.4340 - accuracy: 0.5660\n",
            "Epoch 202/300\n",
            "106/106 [==============================] - 0s 77us/step - loss: -5968.4503 - mae: 0.4528 - mse: 0.4528 - accuracy: 0.5472\n",
            "Epoch 203/300\n",
            "106/106 [==============================] - 0s 90us/step - loss: -6099.7850 - mae: 0.4717 - mse: 0.4717 - accuracy: 0.5283\n",
            "Epoch 204/300\n",
            "106/106 [==============================] - 0s 79us/step - loss: -6203.3762 - mae: 0.4906 - mse: 0.4906 - accuracy: 0.5094\n",
            "Epoch 205/300\n",
            "106/106 [==============================] - 0s 82us/step - loss: -6323.6839 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 206/300\n",
            "106/106 [==============================] - 0s 100us/step - loss: -6446.5910 - mae: 0.4717 - mse: 0.4717 - accuracy: 0.5283\n",
            "Epoch 207/300\n",
            "106/106 [==============================] - 0s 89us/step - loss: -6564.0103 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 208/300\n",
            "106/106 [==============================] - 0s 85us/step - loss: -6701.5597 - mae: 0.4717 - mse: 0.4717 - accuracy: 0.5283\n",
            "Epoch 209/300\n",
            "106/106 [==============================] - 0s 84us/step - loss: -6801.8755 - mae: 0.4528 - mse: 0.4528 - accuracy: 0.5472\n",
            "Epoch 210/300\n",
            "106/106 [==============================] - 0s 84us/step - loss: -6916.6358 - mae: 0.4340 - mse: 0.4340 - accuracy: 0.5660\n",
            "Epoch 211/300\n",
            "106/106 [==============================] - 0s 87us/step - loss: -7004.0291 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 212/300\n",
            "106/106 [==============================] - 0s 103us/step - loss: -7214.4222 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 213/300\n",
            "106/106 [==============================] - 0s 91us/step - loss: -7346.5016 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 214/300\n",
            "106/106 [==============================] - 0s 77us/step - loss: -7464.5801 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 215/300\n",
            "106/106 [==============================] - 0s 92us/step - loss: -7610.6343 - mae: 0.4717 - mse: 0.4717 - accuracy: 0.5283\n",
            "Epoch 216/300\n",
            "106/106 [==============================] - 0s 88us/step - loss: -7745.6396 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 217/300\n",
            "106/106 [==============================] - 0s 103us/step - loss: -7885.9281 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 218/300\n",
            "106/106 [==============================] - 0s 92us/step - loss: -7993.7062 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 219/300\n",
            "106/106 [==============================] - 0s 107us/step - loss: -8143.3745 - mae: 0.4717 - mse: 0.4717 - accuracy: 0.5283\n",
            "Epoch 220/300\n",
            "106/106 [==============================] - 0s 93us/step - loss: -8309.1549 - mae: 0.4528 - mse: 0.4528 - accuracy: 0.5472\n",
            "Epoch 221/300\n",
            "106/106 [==============================] - 0s 105us/step - loss: -8449.6538 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 222/300\n",
            "106/106 [==============================] - 0s 83us/step - loss: -8608.4986 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 223/300\n",
            "106/106 [==============================] - 0s 108us/step - loss: -8691.8700 - mae: 0.4906 - mse: 0.4906 - accuracy: 0.5094\n",
            "Epoch 224/300\n",
            "106/106 [==============================] - 0s 85us/step - loss: -8861.7690 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 225/300\n",
            "106/106 [==============================] - 0s 84us/step - loss: -8989.8485 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 226/300\n",
            "106/106 [==============================] - 0s 93us/step - loss: -9203.9387 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 227/300\n",
            "106/106 [==============================] - 0s 99us/step - loss: -9358.0193 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 228/300\n",
            "106/106 [==============================] - 0s 81us/step - loss: -9528.2861 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 229/300\n",
            "106/106 [==============================] - 0s 95us/step - loss: -9695.7189 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 230/300\n",
            "106/106 [==============================] - 0s 94us/step - loss: -9864.2518 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 231/300\n",
            "106/106 [==============================] - 0s 93us/step - loss: -10037.1602 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 232/300\n",
            "106/106 [==============================] - 0s 104us/step - loss: -10224.0904 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 233/300\n",
            "106/106 [==============================] - 0s 143us/step - loss: -10394.6646 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 234/300\n",
            "106/106 [==============================] - 0s 102us/step - loss: -10545.0188 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 235/300\n",
            "106/106 [==============================] - 0s 96us/step - loss: -10795.6450 - mae: 0.4717 - mse: 0.4717 - accuracy: 0.5283\n",
            "Epoch 236/300\n",
            "106/106 [==============================] - 0s 102us/step - loss: -10934.0714 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 237/300\n",
            "106/106 [==============================] - 0s 116us/step - loss: -11077.7849 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 238/300\n",
            "106/106 [==============================] - 0s 80us/step - loss: -11261.4200 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 239/300\n",
            "106/106 [==============================] - 0s 79us/step - loss: -11458.3048 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 240/300\n",
            "106/106 [==============================] - 0s 93us/step - loss: -11671.1525 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 241/300\n",
            "106/106 [==============================] - 0s 88us/step - loss: -11816.7316 - mae: 0.4906 - mse: 0.4906 - accuracy: 0.5094\n",
            "Epoch 242/300\n",
            "106/106 [==============================] - 0s 96us/step - loss: -11994.1789 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 243/300\n",
            "106/106 [==============================] - 0s 82us/step - loss: -12159.1400 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 244/300\n",
            "106/106 [==============================] - 0s 80us/step - loss: -12328.3067 - mae: 0.4906 - mse: 0.4906 - accuracy: 0.5094\n",
            "Epoch 245/300\n",
            "106/106 [==============================] - 0s 75us/step - loss: -12619.6800 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 246/300\n",
            "106/106 [==============================] - 0s 86us/step - loss: -12641.8092 - mae: 0.4906 - mse: 0.4906 - accuracy: 0.5094\n",
            "Epoch 247/300\n",
            "106/106 [==============================] - 0s 93us/step - loss: -12967.8648 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 248/300\n",
            "106/106 [==============================] - 0s 84us/step - loss: -13222.8151 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 249/300\n",
            "106/106 [==============================] - 0s 84us/step - loss: -13436.2379 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 250/300\n",
            "106/106 [==============================] - 0s 94us/step - loss: -13603.2889 - mae: 0.4340 - mse: 0.4340 - accuracy: 0.5660\n",
            "Epoch 251/300\n",
            "106/106 [==============================] - 0s 76us/step - loss: -13695.3460 - mae: 0.4340 - mse: 0.4340 - accuracy: 0.5660\n",
            "Epoch 252/300\n",
            "106/106 [==============================] - 0s 94us/step - loss: -13813.1805 - mae: 0.4151 - mse: 0.4151 - accuracy: 0.5849\n",
            "Epoch 253/300\n",
            "106/106 [==============================] - 0s 88us/step - loss: -14063.2503 - mae: 0.4340 - mse: 0.4340 - accuracy: 0.5660\n",
            "Epoch 254/300\n",
            "106/106 [==============================] - 0s 76us/step - loss: -14344.1984 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 255/300\n",
            "106/106 [==============================] - 0s 103us/step - loss: -14655.7154 - mae: 0.4528 - mse: 0.4528 - accuracy: 0.5472\n",
            "Epoch 256/300\n",
            "106/106 [==============================] - 0s 90us/step - loss: -14714.2650 - mae: 0.5094 - mse: 0.5094 - accuracy: 0.4906\n",
            "Epoch 257/300\n",
            "106/106 [==============================] - 0s 89us/step - loss: -14914.4436 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 258/300\n",
            "106/106 [==============================] - 0s 109us/step - loss: -15193.7976 - mae: 0.5000 - mse: 0.5000 - accuracy: 0.5000\n",
            "Epoch 259/300\n",
            "106/106 [==============================] - 0s 87us/step - loss: -15455.6161 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 260/300\n",
            "106/106 [==============================] - 0s 94us/step - loss: -15663.3429 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 261/300\n",
            "106/106 [==============================] - 0s 80us/step - loss: -15887.6697 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 262/300\n",
            "106/106 [==============================] - 0s 96us/step - loss: -16148.7193 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 263/300\n",
            "106/106 [==============================] - 0s 82us/step - loss: -16377.7811 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 264/300\n",
            "106/106 [==============================] - 0s 74us/step - loss: -16600.8141 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 265/300\n",
            "106/106 [==============================] - 0s 74us/step - loss: -16847.4221 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 266/300\n",
            "106/106 [==============================] - 0s 93us/step - loss: -17111.0807 - mae: 0.4717 - mse: 0.4717 - accuracy: 0.5283\n",
            "Epoch 267/300\n",
            "106/106 [==============================] - 0s 96us/step - loss: -17325.5206 - mae: 0.4725 - mse: 0.4718 - accuracy: 0.5283\n",
            "Epoch 268/300\n",
            "106/106 [==============================] - 0s 92us/step - loss: -17574.0514 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 269/300\n",
            "106/106 [==============================] - 0s 77us/step - loss: -17837.4590 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 270/300\n",
            "106/106 [==============================] - 0s 106us/step - loss: -18076.7105 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 271/300\n",
            "106/106 [==============================] - 0s 96us/step - loss: -18284.7754 - mae: 0.4528 - mse: 0.4528 - accuracy: 0.5472\n",
            "Epoch 272/300\n",
            "106/106 [==============================] - 0s 145us/step - loss: -18523.8299 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 273/300\n",
            "106/106 [==============================] - 0s 95us/step - loss: -18778.9411 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 274/300\n",
            "106/106 [==============================] - 0s 95us/step - loss: -19087.2334 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 275/300\n",
            "106/106 [==============================] - 0s 116us/step - loss: -19315.4223 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 276/300\n",
            "106/106 [==============================] - 0s 136us/step - loss: -19567.5855 - mae: 0.4717 - mse: 0.4717 - accuracy: 0.5283\n",
            "Epoch 277/300\n",
            "106/106 [==============================] - 0s 131us/step - loss: -19847.7430 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 278/300\n",
            "106/106 [==============================] - 0s 94us/step - loss: -20058.3844 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 279/300\n",
            "106/106 [==============================] - 0s 103us/step - loss: -20380.2235 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 280/300\n",
            "106/106 [==============================] - 0s 111us/step - loss: -20625.8339 - mae: 0.4717 - mse: 0.4717 - accuracy: 0.5283\n",
            "Epoch 281/300\n",
            "106/106 [==============================] - 0s 118us/step - loss: -20885.4164 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 282/300\n",
            "106/106 [==============================] - 0s 88us/step - loss: -21087.7437 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 283/300\n",
            "106/106 [==============================] - 0s 106us/step - loss: -21377.5224 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 284/300\n",
            "106/106 [==============================] - 0s 85us/step - loss: -21651.3496 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 285/300\n",
            "106/106 [==============================] - 0s 86us/step - loss: -21972.5576 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 286/300\n",
            "106/106 [==============================] - 0s 79us/step - loss: -22277.4780 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 287/300\n",
            "106/106 [==============================] - 0s 84us/step - loss: -22544.0227 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 288/300\n",
            "106/106 [==============================] - 0s 86us/step - loss: -22803.2018 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 289/300\n",
            "106/106 [==============================] - 0s 82us/step - loss: -23099.3224 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 290/300\n",
            "106/106 [==============================] - 0s 65us/step - loss: -23378.2852 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 291/300\n",
            "106/106 [==============================] - 0s 80us/step - loss: -23670.2254 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 292/300\n",
            "106/106 [==============================] - 0s 106us/step - loss: -23970.4504 - mae: 0.4434 - mse: 0.4434 - accuracy: 0.5566\n",
            "Epoch 293/300\n",
            "106/106 [==============================] - 0s 109us/step - loss: -24301.0098 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 294/300\n",
            "106/106 [==============================] - 0s 123us/step - loss: -24630.4817 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 295/300\n",
            "106/106 [==============================] - 0s 120us/step - loss: -24890.7167 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 296/300\n",
            "106/106 [==============================] - 0s 122us/step - loss: -25211.7715 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 297/300\n",
            "106/106 [==============================] - 0s 76us/step - loss: -25540.2059 - mae: 0.4717 - mse: 0.4717 - accuracy: 0.5283\n",
            "Epoch 298/300\n",
            "106/106 [==============================] - 0s 119us/step - loss: -25829.2442 - mae: 0.4623 - mse: 0.4623 - accuracy: 0.5377\n",
            "Epoch 299/300\n",
            "106/106 [==============================] - 0s 79us/step - loss: -26010.1876 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n",
            "Epoch 300/300\n",
            "106/106 [==============================] - 0s 111us/step - loss: -26473.2630 - mae: 0.4811 - mse: 0.4811 - accuracy: 0.5189\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f74bb444e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvw-lupmVsAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
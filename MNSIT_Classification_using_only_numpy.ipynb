{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNSIT Classification using only numpy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chettkulkarni/deep_learning/blob/master/MNSIT_Classification_using_only_numpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpomeUjGTQus",
        "colab_type": "text"
      },
      "source": [
        "#MNSIT number classification using library\n",
        "\n",
        "\n",
        "\n",
        "1.   Import all the libraries\n",
        "2.   Load MNSIT dataset, and augument some images to make sure our classifier identifies rotated numbers\n",
        "3.   encode the labels one hot encoded\n",
        "4.   Creating activation functions and derivates of activation function to use during the course of algorithm\n",
        "5.   Number of Iterations, Neurons , layers are decided\n",
        "6. Learning rates is fixed at each layer\n",
        "7. Weights are randomly initialsed and data is passed across the\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-2nbIhRB2J_",
        "colab_type": "text"
      },
      "source": [
        "#Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEfAydpgznAU",
        "colab_type": "code",
        "outputId": "1973d9a7-827d-4e8a-da13-86b36da830a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "import random as random\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "random. seed(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbONqvVVBnD5",
        "colab_type": "text"
      },
      "source": [
        "#Loading the dataset\n",
        "\n",
        "Augument the images,rotate some images to regularise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnReprok7gvr",
        "colab_type": "code",
        "outputId": "42ebb1e1-3b32-4e16-c5ab-20ba2561933e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1))\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train = X_train[0:5000]\n",
        "Y_train = Y_train[0:5000]\n",
        "\n",
        "augument_x=X_train[0:100]\n",
        "augument_y=Y_train[0:100]\n",
        "\n",
        "aug = ImageDataGenerator(rotation_range=90)\n",
        "aug.fit(X_train)\n",
        "full= aug.flow(augument_x, augument_y,batch_size=len(augument_x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNtpeNwCCUl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for images,labels in full:\n",
        "  x_train = np.concatenate((X_train,images),axis = 0)\n",
        "  y_train = np.concatenate((Y_train,labels),axis = 0)\n",
        "  break\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uFN7kzaB7dk",
        "colab_type": "text"
      },
      "source": [
        "#Normalizing image datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOglV1oH3-pZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = (x_train.reshape(len(x_train),28*28))/255\n",
        "labels=y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXhBgU-5IhVF",
        "colab_type": "code",
        "outputId": "2d969dee-4c5d-4a8b-95be-a032e72a14e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "images.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5100, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKQOsw1v0I4W",
        "colab_type": "code",
        "outputId": "e2150e22-8523-4780-a16a-a70f5d292e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_M2JSr4CBLi",
        "colab_type": "text"
      },
      "source": [
        "#Encode labels to have one one hot encoding\n",
        "eg:\n",
        "\n",
        "\n",
        "```\n",
        "0 - 1 0 0 0 0 0 0 0 0 0\n",
        "1 - 0 1 0 0 0 0 0 0 0 0\n",
        "2 - 0 0 1 0 0 0 0 0 0 0\n",
        "3 - 0 0 0 1 0 0 0 0 0 0\n",
        "and so on\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRiyRSsT4NUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hot_labels = np.zeros((len(labels),10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIs2S-k14SSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,l in enumerate(labels):\n",
        "  one_hot_labels[i][l] = 1\n",
        "labels = one_hot_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJoE1j3g09nE",
        "colab_type": "text"
      },
      "source": [
        "Also normalise test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W51EN1tX4eu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images = X_test.reshape(len(X_test),28*28)/255\n",
        "test_labels = np.zeros((len(Y_test),10))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DrC7YPB4qUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,l in enumerate(Y_test):\n",
        "  test_labels[i][l] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs3FH1mCCUZI",
        "colab_type": "text"
      },
      "source": [
        "#Defining different activation function and there derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhJHVfDH4y3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tanh(x):\n",
        "  return np.tanh(x)\n",
        "\n",
        "def tanh2deriv(output):\n",
        "  return 1 - (output ** 2)\n",
        "\n",
        "def relu(x):\n",
        "  return (x>=0)*x\n",
        "\n",
        "def relu2deriv(x):\n",
        "  return x>=0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q71y5tQEBYfl",
        "colab_type": "text"
      },
      "source": [
        "#Number of iterations, and different hidden layer sizes\n",
        "iterations will be the number of times the weights are to be updated till you\n",
        "layeer- number of layers\n",
        "\n",
        "#Setting learning rate per layer - 3 layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RssmQMjT5GNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iterations , hidden_size, hidden_size_2 = (150,100,100)\n",
        "alpha1,alpha2,alpha3 = 2, 2.5 ,3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ANn3SqV5LPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputPixels , num_labels = (784,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8v8wqeDBFbW",
        "colab_type": "text"
      },
      "source": [
        "#batch size "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "papJiWuC5PE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlfUt-jYA88T",
        "colab_type": "text"
      },
      "source": [
        "#Weights between each layer ,randomly selected for the first iteration\n",
        "\n",
        "#**total 3 layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vV6ZcJO5Qg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_0_1 = 0.02*np.random.random((inputPixels,hidden_size))-0.01\n",
        "weights_1_2 = 0.2*np.random.random((hidden_size,hidden_size_2))-0.10\n",
        "weights_2_3 = 0.3*np.random.random((hidden_size_2,num_labels))- 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akTBE4FaArnU",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "for each iteration :-\n",
        "\n",
        "- propogate the layer weghts from input to output layer\n",
        "- compare the output layer with the actual layer, calculate the error\n",
        "- propogate the layer back\n",
        "- using the error recalculate the weights \n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozQS47-k64Yd",
        "colab_type": "text"
      },
      "source": [
        "#also having a dropout masks , Run the back propagation algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B19ROTJa5jCB",
        "colab_type": "code",
        "outputId": "32cf80e7-b99f-4b0b-fc80-145fb10cb328",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "for j in range(iterations):\n",
        "  correct_cnt = 0\n",
        "  for i in range(int(len(images) / batch_size)):\n",
        "    \n",
        "    batch_start, batch_end = ((i * batch_size), ((i + 1)*batch_size))\n",
        "    layer_0 = images[batch_start:batch_end]\n",
        "\n",
        "    layer_1 = tanh(np.dot(layer_0,weights_0_1))\n",
        "    dropout_mask = np.random.randint(2,size=layer_1.shape)\n",
        "    layer_1 *= dropout_mask*2\n",
        "\n",
        "    layer_2 = relu(np.dot(layer_1,weights_1_2))\n",
        "\n",
        "    dropout_mask = np.random.randint(2,size=layer_2.shape)\n",
        "    layer_2 *= dropout_mask*2\n",
        "\n",
        "    layer_3 = relu(np.dot(layer_2,weights_2_3))\n",
        "\n",
        "    for k in range(batch_size):\n",
        "      correct_cnt += int(np.argmax(layer_3[k:k+1])== np.argmax(labels[batch_start+k:batch_start+k+1]))\n",
        "    \n",
        "    layer_3_delta = (labels[batch_start:batch_end] - layer_3) / (batch_size * layer_3.shape[0])\n",
        "    layer_2_delta = layer_3_delta.dot(weights_2_3.T) * relu2deriv(layer_2)\n",
        "    layer_1_delta = layer_2_delta.dot(weights_1_2.T) * tanh2deriv(layer_1)\n",
        "\n",
        "\n",
        "    weights_2_3 += alpha3 * layer_2.T.dot(layer_3_delta)\n",
        "    weights_1_2 += alpha2 * layer_1.T.dot(layer_2_delta)\n",
        "    weights_0_1 += alpha1 * layer_0.T.dot(layer_1_delta)\n",
        "\n",
        "  test_correct_cnt = 0\n",
        "  test_labels_y=[]\n",
        "  original_labels_y=[]\n",
        "  for i in range(len(test_images)):\n",
        "    layer_0 = test_images[i:i+1]\n",
        "    layer_1 = tanh(np.dot(layer_0,weights_0_1))\n",
        "    layer_2 = relu(np.dot(layer_1,weights_1_2))\n",
        "    layer_3 = np.dot(layer_2,weights_2_3)\n",
        "    test_labels_y += [int(np.argmax(layer_3))]\n",
        "    original_labels_y += [np.argmax(test_labels[i:i+1])]\n",
        "    test_correct_cnt += int(np.argmax(layer_3) == np.argmax(test_labels[i:i+1]))\n",
        "  \n",
        "  if(j % 10 == 0):\n",
        "    print(10*'*','iteration:',j)\n",
        "    print('Train Accuracy :- ', str(correct_cnt/float(len(images))))\n",
        "    print('Test  Accuracy :-',str(test_correct_cnt/float(len(test_images))) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "********** iteration: 0\n",
            "Train Accuracy :-  0.21019607843137256\n",
            "Test  Accuracy :- 0.5362\n",
            "********** iteration: 10\n",
            "Train Accuracy :-  0.4031372549019608\n",
            "Test  Accuracy :- 0.6735\n",
            "********** iteration: 20\n",
            "Train Accuracy :-  0.49137254901960786\n",
            "Test  Accuracy :- 0.7111\n",
            "********** iteration: 30\n",
            "Train Accuracy :-  0.5519607843137255\n",
            "Test  Accuracy :- 0.7672\n",
            "********** iteration: 40\n",
            "Train Accuracy :-  0.6280392156862745\n",
            "Test  Accuracy :- 0.8126\n",
            "********** iteration: 50\n",
            "Train Accuracy :-  0.6807843137254902\n",
            "Test  Accuracy :- 0.8417\n",
            "********** iteration: 60\n",
            "Train Accuracy :-  0.7164705882352941\n",
            "Test  Accuracy :- 0.8561\n",
            "********** iteration: 70\n",
            "Train Accuracy :-  0.7429411764705882\n",
            "Test  Accuracy :- 0.865\n",
            "********** iteration: 80\n",
            "Train Accuracy :-  0.7492156862745099\n",
            "Test  Accuracy :- 0.8712\n",
            "********** iteration: 90\n",
            "Train Accuracy :-  0.7717647058823529\n",
            "Test  Accuracy :- 0.8735\n",
            "********** iteration: 100\n",
            "Train Accuracy :-  0.7733333333333333\n",
            "Test  Accuracy :- 0.8758\n",
            "********** iteration: 110\n",
            "Train Accuracy :-  0.7884313725490196\n",
            "Test  Accuracy :- 0.8779\n",
            "********** iteration: 120\n",
            "Train Accuracy :-  0.7858823529411765\n",
            "Test  Accuracy :- 0.8788\n",
            "********** iteration: 130\n",
            "Train Accuracy :-  0.7952941176470588\n",
            "Test  Accuracy :- 0.8809\n",
            "********** iteration: 140\n",
            "Train Accuracy :-  0.7872549019607843\n",
            "Test  Accuracy :- 0.8808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSFCm-roQtYU",
        "colab_type": "text"
      },
      "source": [
        "#confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ2B-oFQM-Qx",
        "colab_type": "code",
        "outputId": "d4780eba-9f8e-45e8-969a-11a4e0e15d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "confusion_matrix(original_labels_y, test_labels_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 953,    0,    1,    4,    0,    5,    9,    2,    6,    0],\n",
              "       [   0, 1086,    1,    2,    1,    3,    4,    0,   38,    0],\n",
              "       [  17,   14,  848,   28,   13,    1,   29,   15,   63,    4],\n",
              "       [  13,    1,   26,  804,    0,   83,    4,   22,   47,   10],\n",
              "       [   0,    2,    2,    0,  890,    0,   22,    1,    2,   63],\n",
              "       [  28,    2,   12,   35,   12,  716,   22,    5,   51,    9],\n",
              "       [  15,    2,   27,    1,   26,   17,  865,    1,    4,    0],\n",
              "       [   4,   21,   24,    2,    9,    0,    0,  897,    9,   62],\n",
              "       [   7,    7,    4,   19,    9,   27,   16,    4,  856,   25],\n",
              "       [  12,    7,    6,    8,   41,    9,    2,   10,   13,  901]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXa-5Q9JQ0fX",
        "colab_type": "text"
      },
      "source": [
        "#accuracy _final iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XabS9roBRHCe",
        "colab_type": "code",
        "outputId": "695ecb77-77d3-4faf-8e35-ee14efa34e8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy_score(original_labels_y, test_labels_y)*100"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88.16000000000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUHm-YJKTHIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
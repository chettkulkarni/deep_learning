{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "customImageDetection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNntUiWgVJYOBYjqEWLM3N9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chettkulkarni/deep_learning/blob/master/assignment%204/Transfer%20Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbx7jqB_ReEw",
        "colab_type": "code",
        "outputId": "823b518d-e876-49f9-a3c8-7fbf06d0a900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "import pandas\n",
        "from fastai.vision import *\n",
        "from keras.preprocessing import image\n",
        "import urllib.request\n",
        "from keras.preprocessing.image import *\n",
        "import keras\n",
        "from keras.layers import *\n",
        "\n",
        "import random\n",
        "random.seed(1)\n",
        "\n",
        "import pydot\n",
        "import keras\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6sqvkanGKmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def downloadImagesCustom(types,folder_name,file_name,url):\n",
        "  print(types,folder_name,file_name,url)\n",
        "  path = Path('food')\n",
        "  \n",
        "  dest = path/types/'images'\n",
        "  dest.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  csv=path/types/'images'/file_name\n",
        "  urllib.request.urlretrieve(url, csv)\n",
        "  \n",
        "  destination=path/types/'images'\n",
        "  download_images(csv, destination, max_pics=200,max_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SloBpoLcRXBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic={}\n",
        "\n",
        "# dic[0]=('train','nature','train_nature.csv','https://raw.githubusercontent.com/chettkulkarni/deep_learning/master/dataset/train_nature.csv')\n",
        "# dic[1]=('test','nature','test_nature.csv','https://raw.githubusercontent.com/chettkulkarni/deep_learning/master/dataset/test_nature.csv')\n",
        "\n",
        "# dic[2]=('train','cats','train_cats.csv','https://raw.githubusercontent.com/chettkulkarni/deep_learning/master/dataset/train_cats.csv')\n",
        "# dic[3]=('test','cats','test_cats.csv','https://raw.githubusercontent.com/chettkulkarni/deep_learning/master/dataset/test_cats.csv')\n",
        "\n",
        "\n",
        "# dic[4]=('train','wolf','train_wolf.csv','https://raw.githubusercontent.com/chettkulkarni/deep_learning/master/dataset/train_wolf.csv')\n",
        "# dic[5]=('test','wolf','test_wolf.csv','https://raw.githubusercontent.com/chettkulkarni/deep_learning/master/dataset/test_wolf.csv')\n",
        "\n",
        "\n",
        "# dic[6]=('train','krishna','train_krishna.csv','https://raw.githubusercontent.com/chettkulkarni/deep_learning/master/dataset/train_krishna.csv')\n",
        "# dic[7]=('test','krishna','test_krishna.csv','https://raw.githubusercontent.com/chettkulkarni/deep_learning/master/dataset/test_krishna.csv')\n",
        "\n",
        "\n",
        "\n",
        "# dic[8]=('train','santa_claus','train_santa_claus.csv','https://raw.githubusercontent.com/chettkulkarni/deep_learning/master/dataset/train_santa_claus.csv')\n",
        "# dic[9]=('test','santa_claus','test_santa_claus.csv','https://raw.githubusercontent.com/chettkulkarni/deep_learning/master/dataset/test_santa_claus.csv')\n",
        "\n",
        "\n",
        "\n",
        "# dic[10]=('train','cars','train_cars.csv','https://raw.githubusercontent.com/chettkulkarni/deep_learning/master/dataset/train_cars.csv')\n",
        "# dic[11]=('test','cars','test_cars.csv','https://raw.githubusercontent.com/chettkulkarni/deep_learning/master/dataset/test_cars.csv')\n",
        "\n",
        "dic={}\n",
        "dic[12]=('train','food','train_food.csv','https://raw.githubusercontent.com/chettkulkarni/deep_learning/master/dataset/train_food.csv')\n",
        "dic[13]=('test','food','test_food.csv','https://raw.githubusercontent.com/chettkulkarni/deep_learning/master/dataset/test_food.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBS6Vn2qRonH",
        "colab_type": "code",
        "outputId": "06bf718c-5015-4a1c-a7d2-92bd7d3ce54e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "for i,j in dic.items():\n",
        "  downloadImagesCustom(j[0],j[1],j[2],j[3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train food train_food.csv https://raw.githubusercontent.com/chettkulkarni/deep_learning/master/dataset/train_food.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "Error  Invalid URL '': No schema supplied. Perhaps you meant http://?\n",
            "test food test_food.csv https://raw.githubusercontent.com/chettkulkarni/deep_learning/master/dataset/test_food.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Error ﻿https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQeuNatrg7Df2k_VVR6maGMx9hLh5hYzRmTg9ImDPBceAF9fgUq&usqp=CAU No connection adapters were found for '\\ufeffhttps://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcQeuNatrg7Df2k_VVR6maGMx9hLh5hYzRmTg9ImDPBceAF9fgUq&usqp=CAU'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATKpw6FZR8D6",
        "colab_type": "code",
        "outputId": "f22e8e84-e14a-4268-a77c-4ededbd4480f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        }
      },
      "source": [
        "!pip3 install tensorflow-gpu==1.13.1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/b1/0ad4ae02e17ddd62109cd54c291e311c4b5fd09b4d0678d3d6ce4159b0f0/tensorflow_gpu-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (345.2MB)\n",
            "\u001b[K     |████████████████████████████████| 345.2MB 48kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.9.0)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 44.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.3.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.28.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.34.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 42.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.13.1) (1.18.3)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (46.1.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0rc3 has requirement tensorflow-estimator<2.3.0,>=2.2.0rc0, but you'll have tensorflow-estimator 1.13.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: mock, tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "Successfully installed mock-4.0.2 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MjSyZRLcSqx",
        "colab_type": "code",
        "outputId": "aa85f556-8731-4a5f-bdca-d5838de706e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "url='https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/pretrained-yolov3.h5'\n",
        "urllib.request.urlretrieve(url, 'pretrained-yolov3.h5')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('pretrained-yolov3.h5', <http.client.HTTPMessage at 0x7f4299097c50>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY4Z4C7Ocvbf",
        "colab_type": "code",
        "outputId": "9f25115e-3dd8-4b8e-96ee-4f1239757f47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "!pip install imageai"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting imageai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/99/4023e191a343fb23f01ae02ac57a5ca58037c310e8d8c62f87638a3bafc7/imageai-2.1.5-py3-none-any.whl (180kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 18.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 30kB 1.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageai) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageai) (1.18.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imageai) (3.2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imageai) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from imageai) (2.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imageai) (1.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->imageai) (1.12.0)\n",
            "Installing collected packages: imageai\n",
            "Successfully installed imageai-2.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRhC1tlldy3X",
        "colab_type": "code",
        "outputId": "cfbf882c-a778-4c7d-ce7c-d0279efac32f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmSYn39keIw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path='/content/drive/My Drive/food'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2_5NA9scCZY",
        "colab_type": "code",
        "outputId": "43da2cfe-2bde-4e35-89e8-4002edf6fe42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "trainer.setDataDirectory(data_directory=path)\n",
        "trainer.setTrainConfig(object_names_array=[\"food\"], batch_size=4, num_experiments=200, train_from_pretrained_model=\"pretrained-yolov3.h5\")\n",
        "trainer.trainModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating anchor boxes for training images and annotation...\n",
            "Average IOU for 9 anchors: 0.79\n",
            "Anchor Boxes generated.\n",
            "Detection configuration saved in  /content/drive/My Drive/food/json/detection_config.json\n",
            "Training on: \t['food']\n",
            "Training with Batch Size:  4\n",
            "Number of Experiments:  200\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/imageai/Detection/Custom/yolo.py:24: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Training with transfer learning from pretrained Model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/200\n",
            "16/16 [==============================] - 552s 35s/step - loss: 168.7140 - yolo_layer_1_loss: 23.0593 - yolo_layer_2_loss: 45.9919 - yolo_layer_3_loss: 99.6627 - val_loss: 184.0752 - val_yolo_layer_1_loss: 28.0833 - val_yolo_layer_2_loss: 57.0110 - val_yolo_layer_3_loss: 116.6524\n",
            "Epoch 2/200\n",
            "16/16 [==============================] - 559s 35s/step - loss: 138.0314 - yolo_layer_1_loss: 17.8383 - yolo_layer_2_loss: 36.8440 - yolo_layer_3_loss: 83.3491 - val_loss: 233.3770 - val_yolo_layer_1_loss: 25.5370 - val_yolo_layer_2_loss: 59.7492 - val_yolo_layer_3_loss: 134.8458\n",
            "Epoch 3/200\n",
            "16/16 [==============================] - 436s 27s/step - loss: 90.5858 - yolo_layer_1_loss: 10.8012 - yolo_layer_2_loss: 22.7838 - yolo_layer_3_loss: 57.0008 - val_loss: 197.1725 - val_yolo_layer_1_loss: 22.5385 - val_yolo_layer_2_loss: 42.0865 - val_yolo_layer_3_loss: 108.8666\n",
            "Epoch 4/200\n",
            "11/16 [===================>..........] - ETA: 2:30 - loss: 80.6733 - yolo_layer_1_loss: 9.5416 - yolo_layer_2_loss: 19.3840 - yolo_layer_3_loss: 51.7476"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9hZnyC9covG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}